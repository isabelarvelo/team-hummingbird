{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "output-file: ask-the-dataset.html\n",
    "title: Ask the Dataset\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook demonstrates the backend logic of a Data Analysis Chatbot. Built with OpenAI's GPT model, this interactive tool allows users to input their API key, the paths to their data, and their questions. The model processes this information to provide insightful answers to the user's queries about their dataset. The AI-powered assistant is designed to understand and analyze data uploaded in CSV format, delivering its analysis in a natural, conversational manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspaces/ai-assisted-coding-final/nbs'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### GPTQuestionsHandler\n",
       "\n",
       ">      GPTQuestionsHandler (api_key)\n",
       "\n",
       "This class interfaces with OpenAI's GPT model. \n",
       "It sends user queries about the dataset to the GPT model and retrieves responses."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### GPTQuestionsHandler\n",
       "\n",
       ">      GPTQuestionsHandler (api_key)\n",
       "\n",
       "This class interfaces with OpenAI's GPT model. \n",
       "It sends user queries about the dataset to the GPT model and retrieves responses."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(GPTQuestionsHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### CSVFileManager\n",
       "\n",
       ">      CSVFileManager ()\n",
       "\n",
       "This class is responsible for handling CSV file operations. \n",
       "It can read one or more CSV files, either from file paths or file-like objects, and concatenate them into a single pandas DataFrame."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### CSVFileManager\n",
       "\n",
       ">      CSVFileManager ()\n",
       "\n",
       "This class is responsible for handling CSV file operations. \n",
       "It can read one or more CSV files, either from file paths or file-like objects, and concatenate them into a single pandas DataFrame."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(CSVFileManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How many rows are there?  \n",
      "\n",
      "Answer: There are 46 rows in the dataset. \n",
      "\n",
      "Question:  Give me the line of code in python to calculate this \n",
      "\n",
      "Answer: Certainly! You can use the pandas library in Python to read the dataset and calculate the number of rows. Here's the line of code to do that:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset\n",
      "data = pd.read_csv('your_file.csv')  # Replace 'your_file.csv' with the actual file name\n",
      "\n",
      "# Calculate the number of rows\n",
      "num_rows = data.shape[0]\n",
      "print(num_rows)\n",
      "```\n",
      "\n",
      "Replace `'your_file.csv'` with the actual file name and use this code to calculate the number of rows in the dataset. \n",
      "\n",
      "Question:  Give me an example of an OTR utterance \n",
      "\n",
      "Answer: Certainly! An example of an OTR (other) utterance from the given dataset is:\n",
      "\"Can someone give me a sentence with an exclamation mark?\"\n",
      "\n",
      "This is an example of an utterance where the speaker is seeking a specific type of response from the audience. \n",
      "\n",
      "Exiting the chat.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    #file_paths_input = input(\"Enter CSV file paths, separated by a comma: \") Can use this if you want the notebook to be interactive\n",
    "    file_paths_input = '../data/009-1.csv, ../data/009-2.csv'\n",
    "    file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "    ai_handler = GPTQuestionsHandler(api_key)\n",
    "\n",
    "    # Initialize the conversation history\n",
    "    history = []\n",
    "    try:\n",
    "        while True:\n",
    "            user_question = input(\"Please enter your question about the data: \")\n",
    "            # Update the history with the user's question\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "            answer = ai_handler.ask_gpt(history, data_frame.to_string(index=False))\n",
    "\n",
    "            print(\"Question: \", user_question,\"\\n\")\n",
    "            print(\"Answer:\", answer, \"\\n\")\n",
    "            \n",
    "            # Ask the user if they want to continue or exit\n",
    "            continue_chat = input(\"Do you have another question? (yes/no): \")\n",
    "            if continue_chat.lower() == 'no':\n",
    "                print(\"Exiting the chat.\")\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred. Please try again.\",e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\" and os.environ.get('NBDEV_PREPARE') is None:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output from the model illustrates that it has the capabilities to remember the conversation and answer follow up questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on code functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of GPT Model Responses with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Can you provide examples of sentences labeled as 'PRS' \n",
      "\n",
      "Answer: Sure! Here are the examples of sentences labeled as 'PRS' from the given data:\n",
      "\n",
      "1. Great example, 'run' is a verb because it is an action.\n",
      "2. Our sentence is now: 'The fast cat runs'.\n",
      "3. Great job, that sentence definitely needed an exclamation mark!\n",
      "4. Great, now our sentence is: 'She reads a book'.\n",
      "5. Great, now our sentence is: 'She runs quickly'.\n",
      "6. Well done, everyone! You have learned a lot today.\n",
      "7. Wonderful! That sentence is showing strong emotion, so it is an exclamatory sentence.\n",
      "8. Great, now our sentence is: 'The book on the table'.\n",
      "9. Well done, everyone! You have learned a lot today.\n",
      "10. I am looking forward to reading your paragraphs.\n",
      "11. Have a great day, and remember to keep practicing your English!\n",
      "\n",
      "These are the examples of sentences labeled as 'PRS' from the given data. \n",
      "\n",
      "Exiting the chat.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file_paths_input = '../data/009-1.csv, ../data/009-2.csv'\n",
    "    file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    try:\n",
    "        api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "        ai_handler = GPTQuestionsHandler(api_key)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize the conversation history\n",
    "    history = []\n",
    "    try:\n",
    "        while True:\n",
    "            user_question = \"Can you provide examples of sentences labeled as 'PRS'\"\n",
    "            # Update the history with the user's question\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "            answer = ai_handler.ask_gpt(history, data_frame.to_string(index=False))\n",
    "\n",
    "            print(\"Question: \", user_question,\"\\n\")\n",
    "            print(\"Answer:\", answer, \"\\n\")\n",
    "            \n",
    "            # Ask the user if they want to continue or exit\n",
    "            continue_chat = \"no\"\n",
    "            if continue_chat.lower() == 'no':\n",
    "                print(\"Exiting the chat.\")\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred. Please try again.\",e)\n",
    "\n",
    "if __name__ == \"__main__\" and os.environ.get('NBDEV_PREPARE') is None:\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What are the unique labels in the label column? \n",
      "\n",
      "Answer: The unique labels in the \"Label\" column are:\n",
      "- PRS\n",
      "- OTR\n",
      "- NaN \n",
      "\n",
      "Exiting the chat.\n"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "#     file_paths_input = '../data/009-1.csv, ../data/009-2.csv'\n",
    "#     file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "\n",
    "#     data_manager = CSVFileManager()\n",
    "#     data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "#     try:\n",
    "#         api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "#         ai_handler = GPTQuestionsHandler(api_key)\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         return\n",
    "\n",
    "#     # Initialize the conversation history\n",
    "#     history = []\n",
    "#     try:\n",
    "#         while True:\n",
    "#             user_question = \"What are the unique labels in the label column?\"\n",
    "#             # Update the history with the user's question\n",
    "#             history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "#             answer = ai_handler.ask_gpt(history, data_frame.to_string(index=False))\n",
    "\n",
    "#             print(\"Question: \", user_question,\"\\n\")\n",
    "#             print(\"Answer:\", answer, \"\\n\")\n",
    "            \n",
    "#             # Ask the user if they want to continue or exit\n",
    "#             continue_chat = \"no\"\n",
    "#             if continue_chat.lower() == 'no':\n",
    "#                 print(\"Exiting the chat.\")\n",
    "#                 break\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(\"An error occurred. Please try again.\",e)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Response to \"How many unique labels are there in the Label column?\"\n",
    "The model correctly identifies three unique labels: 'PRS', 'OTR', and 'NaN'.\n",
    "'NaN' is mentioned as a label, which indicates the model understands 'NaN' (commonly used to represent missing data in pandas DataFrames) as a category. This shows an understanding of data handling conventions.\n",
    "The response indicates the model's ability to interpret and categorize data based on provided information.\n",
    "\n",
    "2. Response to \"Can you provide examples of sentences labeled as 'PRS'\"\n",
    "The model provided a list of sentences which are assumed to be labeled as 'PRS'.\n",
    "The model's response demonstrates its ability to extract and present data based on specified criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two examples, we can see that overall, the model shows a strong understanding of the context and structure of the data. It can differentiate between labels and provide relevant examples. The provided examples seem relevant and accurately categorized based on the 'PRS' label. This indicates the model's effectiveness in filtering and presenting data as per user queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model can provide information based on the data it's been given in the prompt, and can provide the python code to perform analyses, it can't run codes and provide visualizations.\n",
    "\n",
    "\n",
    "The model's responses to queries about the dataset showcase its capabilities in data analysis, context understanding, and relevant information extraction. The model effectively interprets and categorizes data, providing coherent and contextually appropriate responses. \n",
    "\n",
    "Moreover, it has the capabilities to remember the conversation history, to answer follow up questions.\n",
    "\n",
    "These capabilities make it a valuable tool for gaining insights from structured data, such as CSV files, although it's important to remember its limitations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
