{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Functionality for in-the-loop labeling\n",
    "output-file: interactive_labeling.html\n",
    "skip_exec: true\n",
    "title: Interactive Labeling Tool with OpenAI Assistants\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### read_csv\n",
       "\n",
       ">      read_csv (file_path)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### read_csv\n",
       "\n",
       ">      read_csv (file_path)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### process_lines\n",
       "\n",
       ">      process_lines (lines, assistant_manager, context='')\n",
       "\n",
       "Process a list of text lines to assign labels based on the content, using an AI assistant manager.\n",
       "\n",
       "This function takes multiple text lines, combines them with additional context, and submits them to an AI assistant for processing. Each line is expected to be a separate utterance. \n",
       "The AI assistant analyzes the content and returns labels for each line. The labels are filtered to ensure they belong to a predefined set of valid labels. If an error occurs during processing, a default label is assigned to each line.\n",
       "\n",
       "Parameters:\n",
       "- lines (list of str): A list of text lines (utterances) to be processed.\n",
       "- assistant_manager (AssistantManager): An instance of AssistantManager to handle the communication with the AI assistant.\n",
       "- context (str, optional): Additional context to be appended to the text lines before processing. Defaults to an empty string.\n",
       "\n",
       "Returns:\n",
       "- list of tuples: A list where each tuple contains a line and its corresponding label. For example: [('line1', 'NEU'), ('line2', 'OTR')].\n",
       "\n",
       "Raises:\n",
       "- Exception: Captures and prints any exception that occurs during the API call to the assistant manager, with a fallback to default labeling.\n",
       "\n",
       "Note:\n",
       "The function assumes a specific format for the AI assistant's response and predefined valid labels [\"NEU\", \"OTR\", \"PRS\", \"REP\"]. It defaults to \"NEU\" for any label not in the valid set or in case of an error."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### process_lines\n",
       "\n",
       ">      process_lines (lines, assistant_manager, context='')\n",
       "\n",
       "Process a list of text lines to assign labels based on the content, using an AI assistant manager.\n",
       "\n",
       "This function takes multiple text lines, combines them with additional context, and submits them to an AI assistant for processing. Each line is expected to be a separate utterance. \n",
       "The AI assistant analyzes the content and returns labels for each line. The labels are filtered to ensure they belong to a predefined set of valid labels. If an error occurs during processing, a default label is assigned to each line.\n",
       "\n",
       "Parameters:\n",
       "- lines (list of str): A list of text lines (utterances) to be processed.\n",
       "- assistant_manager (AssistantManager): An instance of AssistantManager to handle the communication with the AI assistant.\n",
       "- context (str, optional): Additional context to be appended to the text lines before processing. Defaults to an empty string.\n",
       "\n",
       "Returns:\n",
       "- list of tuples: A list where each tuple contains a line and its corresponding label. For example: [('line1', 'NEU'), ('line2', 'OTR')].\n",
       "\n",
       "Raises:\n",
       "- Exception: Captures and prints any exception that occurs during the API call to the assistant manager, with a fallback to default labeling.\n",
       "\n",
       "Note:\n",
       "The function assumes a specific format for the AI assistant's response and predefined valid labels [\"NEU\", \"OTR\", \"PRS\", \"REP\"]. It defaults to \"NEU\" for any label not in the valid set or in case of an error."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(process_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### label_data\n",
       "\n",
       ">      label_data (unlabeled_text)\n",
       "\n",
       "Prompts the user to label the given input.\n",
       "\n",
       "Args:\n",
       "unlabeled_text (str): The text data that needs labeling.\n",
       "\n",
       "Returns:\n",
       "str: The label provided by the user."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### label_data\n",
       "\n",
       ">      label_data (unlabeled_text)\n",
       "\n",
       "Prompts the user to label the given input.\n",
       "\n",
       "Args:\n",
       "unlabeled_text (str): The text data that needs labeling.\n",
       "\n",
       "Returns:\n",
       "str: The label provided by the user."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(label_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### create_df_from_list\n",
       "\n",
       ">      create_df_from_list (text_list)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### create_df_from_list\n",
       "\n",
       ">      create_df_from_list (text_list)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(create_df_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### increase_batch_size\n",
       "\n",
       ">      increase_batch_size (batch_size, accuracy)\n",
       "\n",
       "Increase batch size if accuracy is above 90%."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### increase_batch_size\n",
       "\n",
       ">      increase_batch_size (batch_size, accuracy)\n",
       "\n",
       "Increase batch size if accuracy is above 90%."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(increase_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### process_batch\n",
       "\n",
       ">      process_batch (unlabeled_data, start_index, batch_size, batch_sizes)\n",
       "\n",
       "Process a batch of data and return the actual batch size which may be less than the batch size if the end of the data is reached."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### process_batch\n",
       "\n",
       ">      process_batch (unlabeled_data, start_index, batch_size, batch_sizes)\n",
       "\n",
       "Process a batch of data and return the actual batch size which may be less than the batch size if the end of the data is reached."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(process_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### get_user_labels\n",
       "\n",
       ">      get_user_labels (batch, assistant_manager, context)\n",
       "\n",
       "Get user labels for a batch of data."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### get_user_labels\n",
       "\n",
       ">      get_user_labels (batch, assistant_manager, context)\n",
       "\n",
       "Get user labels for a batch of data."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_user_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "### calculate_accuracy\n",
       "\n",
       ">      calculate_accuracy (correct_responses, batch_size)\n",
       "\n",
       "Calculate accuracy for a batch of data."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "### calculate_accuracy\n",
       "\n",
       ">      calculate_accuracy (correct_responses, batch_size)\n",
       "\n",
       "Calculate accuracy for a batch of data."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(calculate_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
