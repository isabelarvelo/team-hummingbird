{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive Labeling Tool with OpenAI Assistants\n",
    "> Functionality for in-the-loop labeling "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "skip_exec: True \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp interactive_labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def read_csv(file_path):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df['Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_lines(lines, assistant_manager, context=\"\"):\n",
    "    data = []\n",
    "    additional_context = \"Return a list of labels for each utterance. Each utterance is separated by \\n\"\n",
    "    context += additional_context\n",
    "    assistant_manager.create_thread(context)\n",
    "\n",
    "    all_lines = \"\\n \".join(lines)\n",
    "\n",
    "    try:\n",
    "        completed_run = assistant_manager.submit_message(all_lines)\n",
    "        response_page = assistant_manager.get_response()\n",
    "        messages = [msg for msg in response_page] \n",
    "        assistant_message = messages[-1].content[0].text.value\n",
    "        labels = assistant_message.replace('\\n', ' ').replace(',', ' ').split()\n",
    "\n",
    "        # Check if labels are one of the specified labels\n",
    "        valid_labels = [\"NEU\", \"OTR\", \"PRS\", \"REP\"]\n",
    "        labels = [label if label in valid_labels else \"NEU\" for label in labels]\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exception that occurred during API call\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        # Default to \"NEU\" for all lines in case of an error\n",
    "        labels = [\"NEU\"] * len(lines)\n",
    "\n",
    "    # append tuple (line, label) to data using zip\n",
    "    data = list(zip(lines, labels))\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def label_data(unlabeled_text):\n",
    "    \"\"\"\n",
    "    Prompts the user to label the given input.\n",
    "\n",
    "    Args:\n",
    "    unlabeled_text (str): The text data that needs labeling.\n",
    "\n",
    "    Returns:\n",
    "    str: The label provided by the user.\n",
    "    \"\"\"\n",
    "    #print(f\"Label the following line: {unlabeled_text}\")\n",
    "    label = input(\"Enter the correct label: \")\n",
    "    while label not in [\"NEU\", \"OTR\", \"PRS\", \"REP\"]:\n",
    "        print(\"Invalid label. Please enter a valid label.\")\n",
    "        label = input(\"Enter the correct label: \")\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_df_from_list(text_list):\n",
    "    import pandas as pd \n",
    "    return pd.DataFrame(text_list, columns=[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def increase_batch_size(batch_size, accuracy):\n",
    "    if accuracy <= 0.90:\n",
    "        batch_size = 5\n",
    "    elif accuracy > 0.90:\n",
    "        batch_size = 10\n",
    "    return batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def process_batch(unlabeled_data, start_index, batch_size, batch_sizes):\n",
    "    end_of_batch = min(start_index + batch_size, len(unlabeled_data))\n",
    "    actual_batch = unlabeled_data[start_index:end_of_batch]\n",
    "    actual_batch_size = len(actual_batch)\n",
    "    batch_sizes.append(actual_batch_size)  # Actual number of items in the batch\n",
    "    return actual_batch, actual_batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_user_labels(batch, assistant_manager, context):\n",
    "    import time \n",
    "    predictions = process_lines(batch, assistant_manager, context)\n",
    "    labeled_data = []\n",
    "    correct_responses = 0\n",
    "\n",
    "    for text, prediction in predictions:\n",
    "        print(f\"Predicted for '{text}': {prediction}\")\n",
    "        time.sleep(1)\n",
    "        user_decision = input(f\"Do you agree with this label? (Y/N): \")\n",
    "\n",
    "        correct_label = label_data(text) if user_decision.lower() != 'y' else prediction\n",
    "        correct_responses += correct_label == prediction\n",
    "        context += f\"\\nuser: '{text}'\\nassistant: '{correct_label}'\"\n",
    "        labeled_data.append((text, correct_label))\n",
    "\n",
    "    return labeled_data, correct_responses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_accuracy(correct_responses, batch_size):\n",
    "    return correct_responses / batch_size if batch_size > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
