{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook demonstrates the backend logic of a Data Analysis Chatbot. Built with OpenAI's GPT model, this interactive tool allows users to input their API key, the paths to their data, and their questions. The model processes this information to provide insightful answers to the user's queries about their dataset. The AI-powered assistant is designed to understand and analyze data uploaded in CSV format, delivering its analysis in a natural, conversational manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp AskTheDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import os\n",
    "import getpass\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from io import StringIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CSVFileManager:\n",
    "    \"\"\"This class is responsible for handling CSV file operations. \n",
    "    It can read one or more CSV files, either from file paths or file-like objects, and concatenate them into a\n",
    "    single pandas DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data_frame = None\n",
    "\n",
    "    def load_data(self, files):\n",
    "        \n",
    "        if not files:\n",
    "            raise ValueError(\"No files provided.\")\n",
    "\n",
    "        data_frames = []\n",
    "        for file in files:\n",
    "            # Check if the file is a string (path) or a file-like object\n",
    "            if isinstance(file, str):\n",
    "                df = pd.read_csv(file)\n",
    "            else:  # Assuming file-like object\n",
    "                df = pd.read_csv(file)\n",
    "            data_frames.append(df)\n",
    "\n",
    "        self.data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "        return self.data_frame\n",
    "\n",
    "class GPTQuestionsHandler:\n",
    "    \"\"\"This class interfaces with OpenAI's GPT model. \n",
    "    It sends user queries about the dataset to the GPT model and retrieves responses.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "\n",
    "        # Initializes the OpenAI API client\n",
    "\n",
    "        self.api_key = api_key\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def ask_gpt(self, question, data):\n",
    "        \"\"\"\n",
    "        Sends a question and data to the OpenAI API and retrieves the response\n",
    "        Arguments: The user's question about the data\n",
    "        Data is input to the model in string format\n",
    "        Model returns the response from the API\n",
    "        \"\"\"\n",
    "\n",
    "        system_message = (\"You are a helpful assistant skilled at data science and data analysis. \"\n",
    "                          \"You are an expert at reading files, interpreting them and also writing python codes. \"\n",
    "                          \"Here is the data you need to work with:\\n\" + data)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            temperature=1,\n",
    "            max_tokens=320,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": question}\n",
    "            ])\n",
    "        return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How many rows are in the data? Please also give the code to find out \n",
      "\n",
      "Answer: To find out the number of rows in the data, we can use the `shape` attribute of the DataFrame. The `shape` attribute returns a tuple representing the dimensions of the DataFrame, in the form (rows, columns).\n",
      "\n",
      "Here's the code to accomplish this in Python using the `pandas` library:\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Assuming the data is stored in a variable called 'df'\n",
      "num_rows = df.shape[0]\n",
      "print(\"Number of rows in the data:\", num_rows)\n",
      "```\n",
      "\n",
      "When you run this code for your dataset, it will output the number of rows in the data. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def main():\n",
    "    try:\n",
    "        file_paths_input = input(\"Enter CSV file paths, separated by a comma: \")\n",
    "        file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "    except:\n",
    "        file_paths = ['../data/009-1.csv']\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "    ai_handler = GPTQuestionsHandler(api_key)\n",
    "\n",
    "\n",
    "    try:\n",
    "        user_question = input(\"Please enter your question about the data: \")\n",
    "        answer = ai_handler.ask_gpt(user_question, data_frame.to_string(index=False))\n",
    "\n",
    "        print(\"Question: \", user_question,\"\\n\")\n",
    "        print(\"Answer:\", answer, \"\\n\")\n",
    "    except:\n",
    "        print(\"An error occurred. Please try again.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on code functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of GPT Model Responses with examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Can you provide examples of sentences labeled as 'PRS' \n",
      "\n",
      "Answer: Sure! Here are some examples of sentences labeled as 'PRS':\n",
      "\n",
      "1. Great example, 'run' is a verb because it is an action.\n",
      "2. That sentence definitely needed an exclamation mark!\n",
      "3. She reads a book.\n",
      "4. She runs quickly.\n",
      "5. That's a perfect example! Declarative sentences end with a period.\n",
      "6. Great job! That is indeed an interrogative sentence.\n",
      "7. Wonderful! That sentence is showing strong emotion, so it is an exclamatory sentence.\n",
      "8. The book on the table.\n",
      "\n",
      "These sentences are labeled as 'PRS' in the dataset. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "def main():\n",
    "    file_paths_input = '../data/009-1.csv, ../data/009-2.csv'\n",
    "    file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    try:\n",
    "        api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "        ai_handler = GPTQuestionsHandler(api_key)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        user_question = \"Can you provide examples of sentences labeled as 'PRS'\"\n",
    "        answer = ai_handler.ask_gpt(user_question, data_frame.to_string(index=False))\n",
    "\n",
    "        print(\"Question: \", user_question,\"\\n\")\n",
    "        print(\"Answer:\", answer, \"\\n\")\n",
    "    except:\n",
    "        print(\"An error occurred. Please try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What are the unique labels in the Label column? \n",
      "\n",
      "Answer: The unique labels in the \"Label\" column are:\n",
      "- PRS (Personal Response)\n",
      "- OTR (Others' Response)\n",
      "- NaN (No Label) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "def main():\n",
    "    file_paths_input = '../data/009-1.csv'\n",
    "    file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "    ai_handler = GPTQuestionsHandler(api_key)\n",
    "\n",
    "    try:\n",
    "        user_question = \"What are the unique labels in the Label column?\"\n",
    "        answer = ai_handler.ask_gpt(user_question, data_frame.to_string(index=False))\n",
    "        print(\"Question: \", user_question,\"\\n\")\n",
    "        print(\"Answer:\", answer, \"\\n\")\n",
    "    except:\n",
    "        print(\"An error occurred. Please try again.\")\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Response to \"How many unique labels are there in the Label column?\"\n",
    "The model correctly identifies three unique labels: 'PRS', 'OTR', and 'NaN'.\n",
    "'NaN' is mentioned as a label, which indicates the model understands 'NaN' (commonly used to represent missing data in pandas DataFrames) as a category. This shows an understanding of data handling conventions.\n",
    "The response indicates the model's ability to interpret and categorize data based on provided information.\n",
    "\n",
    "2. Response to \"Can you provide examples of sentences labeled as 'PRS'\"\n",
    "The model provided a list of sentences which are assumed to be labeled as 'PRS'.\n",
    "The model's response demonstrates its ability to extract and present data based on specified criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two examples, we can see that overall, the model shows a strong understanding of the context and structure of the data. It can differentiate between labels and provide relevant examples. The provided examples seem relevant and accurately categorized based on the 'PRS' label. This indicates the model's effectiveness in filtering and presenting data as per user queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model can provide information based on the data it's been given in the prompt, and can provide the python code to perform analyses, it can't run codes and provide visualizations.\n",
    "\n",
    "\n",
    "The model's responses to queries about the dataset showcase its capabilities in data analysis, context understanding, and relevant information extraction. The model effectively interprets and categorizes data, providing coherent and contextually appropriate responses. These capabilities make it a valuable tool for gaining insights from structured data, such as CSV files, although it's important to remember its limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
