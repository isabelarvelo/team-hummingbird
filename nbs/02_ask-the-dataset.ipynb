{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook demonstrates the backend logic of a Data Analysis Chatbot. Built with OpenAI's GPT model, this interactive tool allows users to input their API key, the paths to their data, and their questions. The model processes this information to provide insightful answers to the user's queries about their dataset. The AI-powered assistant is designed to understand and analyze data uploaded in CSV format, delivering its analysis in a natural, conversational manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp AskTheDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import os\n",
    "import getpass\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from io import StringIO\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CSVFileManager:\n",
    "    \"\"\"This class is responsible for handling CSV file operations. \n",
    "    It can read one or more CSV files, either from file paths or file-like objects, and concatenate them into a\n",
    "    single pandas DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data_frame = None\n",
    "\n",
    "    def load_data(self, files):\n",
    "        \n",
    "        if not files:\n",
    "            raise ValueError(\"No files provided.\")\n",
    "\n",
    "        data_frames = []\n",
    "        for file in files:\n",
    "            # Check if the file is a string (path) or a file-like object\n",
    "            if isinstance(file, str):\n",
    "                df = pd.read_csv(file)\n",
    "            else:  # Assuming file-like object\n",
    "                df = pd.read_csv(file)\n",
    "            data_frames.append(df)\n",
    "\n",
    "        self.data_frame = pd.concat(data_frames, ignore_index=True)\n",
    "        return self.data_frame\n",
    "\n",
    "class GPTQuestionsHandler:\n",
    "    \"\"\"This class interfaces with OpenAI's GPT model. \n",
    "    It sends user queries about the dataset to the GPT model and retrieves responses.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "\n",
    "        # Initializes the OpenAI API client\n",
    "\n",
    "        self.api_key = api_key\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "        self.client = OpenAI()\n",
    "\n",
    "    def ask_gpt(self, history, data):\n",
    "        \"\"\"\n",
    "        Sends a question and data to the OpenAI API and retrieves the response\n",
    "        Arguments: The user's question about the data\n",
    "        Data is input to the model in string format\n",
    "        Model returns the response from the API\n",
    "        \"\"\"\n",
    "        \n",
    "        system_message = {\n",
    "            \"role\": \"system\", \n",
    "            \"content\":(\"You are a helpful assistant skilled at data science and data analysis. \"\n",
    "                          \"You are an expert at reading files, interpreting them and also writing python codes. \"\n",
    "                          \"Here is the data you need to work with:\\n\" + data)}\n",
    "        \n",
    "        # Create a copy of history to include system message for API call\n",
    "        messages_for_api = [system_message] + history\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            temperature=0.7,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            messages=messages_for_api)\n",
    "        answer= response.choices[0].message.content\n",
    "        # Update the conversation history with the new response\n",
    "        history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        \n",
    "        return answer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  How many rows are there? \n",
      "\n",
      "Answer: The given dataset has 36 rows. \n",
      "\n",
      "Question:  Give me the line of code in python to calculate this \n",
      "\n",
      "Answer: Certainly! You can use the following line of code in Python to calculate the number of rows in a dataset using the pandas library:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "\n",
      "# Load the dataset into a pandas DataFrame\n",
      "data = pd.read_csv('your_file.csv')  # Replace 'your_file.csv' with the actual file name\n",
      "\n",
      "# Calculate the number of rows\n",
      "num_rows = data.shape[0]\n",
      "print(num_rows)\n",
      "```\n",
      "\n",
      "Replace 'your_file.csv' with the actual file name or file path of the dataset. This code will load the dataset into a pandas DataFrame and then calculate the number of rows in the dataset. \n",
      "\n",
      "Exiting the chat.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "def main():\n",
    "    try:\n",
    "        file_paths_input = input(\"Enter CSV file paths, separated by a comma: \")\n",
    "        file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "    except:\n",
    "        file_paths = ['../data/009-1.csv']\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "    ai_handler = GPTQuestionsHandler(api_key)\n",
    "\n",
    "    # Initialize the conversation history\n",
    "    history = []\n",
    "    try:\n",
    "        while True:\n",
    "            user_question = input(\"Please enter your question about the data: \")\n",
    "            # Update the history with the user's question\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "            answer = ai_handler.ask_gpt(history, data_frame.to_string(index=False))\n",
    "\n",
    "            print(\"Question: \", user_question,\"\\n\")\n",
    "            print(\"Answer:\", answer, \"\\n\")\n",
    "            \n",
    "            # Ask the user if they want to continue or exit\n",
    "            continue_chat = input(\"Do you have another question? (yes/no): \")\n",
    "            if continue_chat.lower() == 'no':\n",
    "                print(\"Exiting the chat.\")\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred. Please try again.\",e)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output from the model illustrates that it has the capabilities to remember the conversation and answer follow up questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commentary on code functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of GPT Model Responses with examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Can you provide examples of sentences labeled as 'PRS' \n",
      "\n",
      "Answer: Sure! Here are the examples of sentences labeled as 'PRS' from the given data:\n",
      "\n",
      "1. Great example, 'run' is a verb because it is an action.\n",
      "2. Our sentence is now: 'The fast cat runs'.\n",
      "3. Great job, that sentence definitely needed an exclamation mark!\n",
      "4. Great, now our sentence is: 'She reads a book'.\n",
      "5. Great, now our sentence is: 'She runs quickly'.\n",
      "6. Well done, everyone! You have learned a lot today.\n",
      "7. Wonderful! That sentence is showing strong emotion, so it is an exclamatory sentence.\n",
      "8. Great, now our sentence is: 'The book on the table'.\n",
      "9. Well done, everyone! You have learned a lot today.\n",
      "10. I am looking forward to reading your paragraphs.\n",
      "11. Have a great day, and remember to keep practicing your English!\n",
      "\n",
      "These are the examples of sentences labeled as 'PRS' from the given data. \n",
      "\n",
      "Exiting the chat.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "def main():\n",
    "    file_paths_input = '../data/009-1.csv, ../data/009-2.csv'\n",
    "    file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    try:\n",
    "        api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "        ai_handler = GPTQuestionsHandler(api_key)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize the conversation history\n",
    "    history = []\n",
    "    try:\n",
    "        while True:\n",
    "            user_question = \"Can you provide examples of sentences labeled as 'PRS'\"\n",
    "            # Update the history with the user's question\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "            answer = ai_handler.ask_gpt(history, data_frame.to_string(index=False))\n",
    "\n",
    "            print(\"Question: \", user_question,\"\\n\")\n",
    "            print(\"Answer:\", answer, \"\\n\")\n",
    "            \n",
    "            # Ask the user if they want to continue or exit\n",
    "            continue_chat = \"no\"\n",
    "            if continue_chat.lower() == 'no':\n",
    "                print(\"Exiting the chat.\")\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred. Please try again.\",e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What are the unique labels in the label column? \n",
      "\n",
      "Answer: The unique labels in the \"Label\" column are:\n",
      "- PRS\n",
      "- OTR\n",
      "- NaN \n",
      "\n",
      "Exiting the chat.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "def main():\n",
    "    file_paths_input = '../data/009-1.csv, ../data/009-2.csv'\n",
    "    file_paths = [path.strip() for path in file_paths_input.split(',')]\n",
    "\n",
    "    data_manager = CSVFileManager()\n",
    "    data_frame = data_manager.load_data(file_paths)\n",
    "\n",
    "    try:\n",
    "        api_key = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "        ai_handler = GPTQuestionsHandler(api_key)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    # Initialize the conversation history\n",
    "    history = []\n",
    "    try:\n",
    "        while True:\n",
    "            user_question = \"What are the unique labels in the label column?\"\n",
    "            # Update the history with the user's question\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "\n",
    "            answer = ai_handler.ask_gpt(history, data_frame.to_string(index=False))\n",
    "\n",
    "            print(\"Question: \", user_question,\"\\n\")\n",
    "            print(\"Answer:\", answer, \"\\n\")\n",
    "            \n",
    "            # Ask the user if they want to continue or exit\n",
    "            continue_chat = \"no\"\n",
    "            if continue_chat.lower() == 'no':\n",
    "                print(\"Exiting the chat.\")\n",
    "                break\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred. Please try again.\",e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Response to \"How many unique labels are there in the Label column?\"\n",
    "The model correctly identifies three unique labels: 'PRS', 'OTR', and 'NaN'.\n",
    "'NaN' is mentioned as a label, which indicates the model understands 'NaN' (commonly used to represent missing data in pandas DataFrames) as a category. This shows an understanding of data handling conventions.\n",
    "The response indicates the model's ability to interpret and categorize data based on provided information.\n",
    "\n",
    "2. Response to \"Can you provide examples of sentences labeled as 'PRS'\"\n",
    "The model provided a list of sentences which are assumed to be labeled as 'PRS'.\n",
    "The model's response demonstrates its ability to extract and present data based on specified criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above two examples, we can see that overall, the model shows a strong understanding of the context and structure of the data. It can differentiate between labels and provide relevant examples. The provided examples seem relevant and accurately categorized based on the 'PRS' label. This indicates the model's effectiveness in filtering and presenting data as per user queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model can provide information based on the data it's been given in the prompt, and can provide the python code to perform analyses, it can't run codes and provide visualizations.\n",
    "\n",
    "\n",
    "The model's responses to queries about the dataset showcase its capabilities in data analysis, context understanding, and relevant information extraction. The model effectively interprets and categorizes data, providing coherent and contextually appropriate responses. \n",
    "\n",
    "Moreover, it has the capabilities to remember the conversation history, to answer follow up questions.\n",
    "\n",
    "These capabilities make it a valuable tool for gaining insights from structured data, such as CSV files, although it's important to remember its limitations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
