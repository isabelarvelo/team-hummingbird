{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI Assistant Example (to be deleted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an example of how the module can be used for classification or other tasks. I will probably add some of this functionality into the module for ease of use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:26.269167Z",
     "start_time": "2023-12-08T22:53:26.262035Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import pandas as pd \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:33.944971Z",
     "start_time": "2023-12-08T22:53:26.634563Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:36.187473Z",
     "start_time": "2023-12-08T22:53:36.177727Z"
    }
   },
   "outputs": [],
   "source": [
    "from ai_assisted_coding_final import assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:36.661163Z",
     "start_time": "2023-12-08T22:53:36.652379Z"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:37.943989Z",
     "start_time": "2023-12-08T22:53:37.939163Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant_manager = assistant.OpenAIAssistantManager(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:38.864692Z",
     "start_time": "2023-12-08T22:53:38.501838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_2LISAuDvQW0WkVlsHkArGX3h\n"
     ]
    }
   ],
   "source": [
    "assistant = assistant_manager.create_assistant(\"ReTeach Assistant 6\",\n",
    "                                                description = \"You are the co-founder of an ed-tech startup training an automated teacher feedback tool to label classroom transcripts\",  \n",
    "                                                instructions= \"Generate the most probable label out of these three for each sentence I provide: OTR (opportunity to respond), PRS (praise), REP (reprimand), or NEU (neutral). Please return just the three letter code.\",\n",
    "                                                model = \"gpt-3.5-turbo\", \n",
    "                                                tools = [{\"type\": \"code_interpreter\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:40.538768Z",
     "start_time": "2023-12-08T22:53:40.533190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Assistant(id='asst_2LISAuDvQW0WkVlsHkArGX3h', created_at=1702076018, description='You are the co-founder of an ed-tech startup training an automated teacher feedback tool to label classroom transcripts', file_ids=[], instructions='Generate the most probable label out of these three for each sentence I provide: OTR (opportunity to respond), PRS (praise), REP (reprimand), or NEU (neutral). Please return just the three letter code.', metadata={}, model='gpt-3.5-turbo', name='ReTeach Assistant 6', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_manager.current_assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Without File - feeding in line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:42.899687Z",
     "start_time": "2023-12-08T22:53:42.692511Z"
    }
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': \"No assistant found with id 'asst_1jBtgFga9hc1pHZE7Djb0YmD'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFoundError\u001B[0m                             Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This is how you retrive an assistant you already created so you don't create a new one everytime you run the code, the id is printed when you create it \u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43massistant_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve_assistant\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43masst_1jBtgFga9hc1pHZE7Djb0YmD\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/team-hummingbird/team-hummingbird/ai_assisted_coding_final/assistant.py:54\u001B[0m, in \u001B[0;36mOpenAIAssistantManager.retrieve_assistant\u001B[0;34m(self, assistant_id)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mretrieve_assistant\u001B[39m(\u001B[38;5;28mself\u001B[39m, assistant_id):\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_assistant \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massistants\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43massistant_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcurrent_assistant\n",
      "File \u001B[0;32m~/Documents/pdf/venv/lib/python3.10/site-packages/openai/resources/beta/assistants/assistants.py:139\u001B[0m, in \u001B[0;36mAssistants.retrieve\u001B[0;34m(self, assistant_id, extra_headers, extra_query, extra_body, timeout)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;124;03mRetrieves an assistant.\u001B[39;00m\n\u001B[1;32m    128\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    138\u001B[0m extra_headers \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOpenAI-Beta\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massistants=v1\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m(extra_headers \u001B[38;5;129;01mor\u001B[39;00m {})}\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/assistants/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43massistant_id\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmake_request_options\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_headers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_query\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_query\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextra_body\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_body\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mAssistant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/pdf/venv/lib/python3.10/site-packages/openai/_base_client.py:1039\u001B[0m, in \u001B[0;36mSyncAPIClient.get\u001B[0;34m(self, path, cast_to, options, stream, stream_cls)\u001B[0m\n\u001B[1;32m   1036\u001B[0m opts \u001B[38;5;241m=\u001B[39m FinalRequestOptions\u001B[38;5;241m.\u001B[39mconstruct(method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget\u001B[39m\u001B[38;5;124m\"\u001B[39m, url\u001B[38;5;241m=\u001B[39mpath, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[1;32m   1037\u001B[0m \u001B[38;5;66;03m# cast is required because mypy complains about returning Any even though\u001B[39;00m\n\u001B[1;32m   1038\u001B[0m \u001B[38;5;66;03m# it understands the type variables\u001B[39;00m\n\u001B[0;32m-> 1039\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cast(ResponseT, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Documents/pdf/venv/lib/python3.10/site-packages/openai/_base_client.py:856\u001B[0m, in \u001B[0;36mSyncAPIClient.request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    847\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    848\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    849\u001B[0m     cast_to: Type[ResponseT],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    854\u001B[0m     stream_cls: \u001B[38;5;28mtype\u001B[39m[_StreamT] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    855\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ResponseT \u001B[38;5;241m|\u001B[39m _StreamT:\n\u001B[0;32m--> 856\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcast_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcast_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream_cls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream_cls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m        \u001B[49m\u001B[43mremaining_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremaining_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/pdf/venv/lib/python3.10/site-packages/openai/_base_client.py:908\u001B[0m, in \u001B[0;36mSyncAPIClient._request\u001B[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001B[0m\n\u001B[1;32m    905\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mis_closed:\n\u001B[1;32m    906\u001B[0m         err\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m--> 908\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_status_error_from_response(err\u001B[38;5;241m.\u001B[39mresponse) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    909\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m httpx\u001B[38;5;241m.\u001B[39mTimeoutException \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    910\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mNotFoundError\u001B[0m: Error code: 404 - {'error': {'message': \"No assistant found with id 'asst_1jBtgFga9hc1pHZE7Djb0YmD'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "# This is how you retrive an assistant you already created so you don't create a new one everytime you run the code, the id is printed when you create it \n",
    "assistant_manager.retrieve_assistant(\"asst_1jBtgFga9hc1pHZE7Djb0YmD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:45.158722Z",
     "start_time": "2023-12-08T22:53:45.150708Z"
    }
   },
   "outputs": [],
   "source": [
    "#my_assistant = client.beta.assistants.retrieve(\"asst_zcB4MoSc2EXEQdvM3MIJNsrf\")\n",
    "#print(my_assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T22:53:46.171185Z",
     "start_time": "2023-12-08T22:53:45.973067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Thread(id='thread_MbaT0BDFFWxijs6tDK8gdn4h', created_at=1702076026, metadata={}, object='thread')"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_manager.create_thread(\"I am going to provide several sentences. Do not respond with anything for each other than the three label you predict.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to play around with this more in the openai playground in terms of the inputs/outputs but its a start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.626480Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant_manager.send_message(\"Can someone replace 'happy' with a synonym? Please return only the three later label.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.628290Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant_manager.send_message(\"For homework, please write a short story using synonyms, antonyms, and homophones. Please return only the three later label.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.630224Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant_manager.send_message(\"I am looking forward to reading your stories. Please return only the three later label.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.632172Z"
    }
   },
   "outputs": [],
   "source": [
    "#result = assistant_manager.run_assistant()\n",
    "run = assistant_manager.run_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.633304Z"
    }
   },
   "outputs": [],
   "source": [
    "for thread_message in run.data:\n",
    "    # Iterate over the 'content' attribute of the ThreadMessage, which is a list\n",
    "    for content_item in thread_message.content:\n",
    "        # Assuming content_item is a MessageContentText object with a 'text' attribute\n",
    "        # and that 'text' has a 'value' attribute, print it\n",
    "        print(content_item.text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.634312Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant.retrieve_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.635310Z"
    }
   },
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=\"thread_maAUdMLifogaELysO3lxuae1\",\n",
    "  assistant_id=\"asst_zcB4MoSc2EXEQdvM3MIJNsrf\"\n",
    ")\n",
    "print(run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.636390Z"
    }
   },
   "outputs": [],
   "source": [
    "file = assistant_manager.add_file(\"data/009-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.637628Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant = assistant_manager.create_assistant(\"ReTeach Assistant F\",\n",
    "                                                description = \"You are the co-founder of an ed-tech startup training an automated teacher feedback tool to label classroom transcripts\",  \n",
    "                                                instructions= \"Generate the most probable label out of these three for each sentence I provide: OTR (opportunity to respond), PRS (praise), REP (reprimand), or NEU (neutral). Please return just the three letter code.\",\n",
    "                                                model = \"gpt-3.5-turbo\", \n",
    "                                                tools = [{\"type\": \"code_interpreter\"}], \n",
    "                                                file_id = file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.638790Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant_manager.create_thread(\"Classify the first 5 rows in the file I just uploaded. Please return only the three later label for each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T08:34:57.667287Z",
     "start_time": "2023-12-08T08:34:57.639610Z"
    }
   },
   "outputs": [],
   "source": [
    "run = assistant_manager.run_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.640347Z"
    }
   },
   "outputs": [],
   "source": [
    "for thread_message in run.data:\n",
    "    # Iterate over the 'content' attribute of the ThreadMessage, which is a list\n",
    "    for content_item in thread_message.content:\n",
    "        # Assuming content_item is a MessageContentText object with a 'text' attribute\n",
    "        # and that 'text' has a 'value' attribute, print it\n",
    "        print(content_item.text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.641160Z"
    }
   },
   "outputs": [],
   "source": [
    "assistant_manager.send_message(\"Please classify the next 5 rows in the file I just uploaded. Please return only the three later label for each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.642040Z"
    }
   },
   "outputs": [],
   "source": [
    "run = assistant_manager.run_assistant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.643088Z"
    }
   },
   "outputs": [],
   "source": [
    "for thread_message in run.data:\n",
    "    # Iterate over the 'content' attribute of the ThreadMessage, which is a list\n",
    "    for content_item in thread_message.content:\n",
    "        # Assuming content_item is a MessageContentText object with a 'text' attribute\n",
    "        # and that 'text' has a 'value' attribute, print it\n",
    "        print(content_item.text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.644243Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-08T08:34:57.645347Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
